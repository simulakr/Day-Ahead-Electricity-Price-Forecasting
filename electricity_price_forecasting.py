# -*- coding: utf-8 -*-
"""Electricity-Price-Forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11z4rmwFrWD-TxU5to8YPk2KmPuDUhfUb
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict, cross_validate
from sklearn import model_selection
from sklearn.model_selection import TimeSeriesSplit
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import BaggingRegressor
from warnings import filterwarnings
import shap
filterwarnings('ignore')
color_pal = sns.color_palette()
plt.style.use('fivethirtyeight')
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 500)
import matplotlib.pylab as plt
import matplotlib.dates as mdates
from statsmodels.tsa.seasonal import seasonal_decompose

"""# Data Preprocessing"""

# Market Clearing Price / Piyasa Takas Fiyatı
mcp1 = pd.read_csv('/content/Piyasa_Takas_Fiyati-30102023-30102024.csv', sep=';')
mcp2 = pd.read_csv('/content/Piyasa_Takas_Fiyati-30102024-30102025.csv', sep=';')
mcp = pd.concat([mcp1, mcp2], axis=0)
mcp.head()

# Production / Üretim
production1 = pd.read_csv('Gercek_Zamanli_Uretim-30102023-30012024.csv', sep=';')
production2 = pd.read_csv('Gercek_Zamanli_Uretim-30012024-30042024.csv', sep=';')
production3 = pd.read_csv('Gercek_Zamanli_Uretim-30042024-30072024.csv', sep=';')
production4 = pd.read_csv('Gercek_Zamanli_Uretim-30072024-30102024.csv', sep=';')
production5 = pd.read_csv('Gercek_Zamanli_Uretim-30102024-30012025.csv', sep=';')
production6 = pd.read_csv('Gercek_Zamanli_Uretim-30012025-30042025.csv', sep=';')
production7 = pd.read_csv('Gercek_Zamanli_Uretim-30042025-30072025.csv', sep=';')
production8 = pd.read_csv('Gercek_Zamanli_Uretim-30072025-30102025.csv', sep=';')

production = pd.concat([production1, production2, production3, production4, production5, production6, production7, production8], axis=0)
production.head()

# Consumption / Tüketim
consumption1 = pd.read_csv('Gercek_Zamanli_Tuketim-30102023-30102024.csv', sep=';')
consumption2 = pd.read_csv('Gercek_Zamanli_Tuketim-30102024-30102025.csv', sep=';')

consumption = pd.concat([consumption1, consumption2], axis=0)
consumption.head()

mcp.info()

production.info()

production.isnull().sum().sort_values(ascending=False).head(5)

consumption.info()

"""## Duplicated Rows"""

mcp.drop_duplicates(inplace=True)
production.drop_duplicates(inplace=True)
consumption.drop_duplicates(inplace=True)

"""## NA Values"""

mcp.dropna(inplace=True)
production.dropna(inplace=True)
consumption.dropna(inplace=True)

"""# Type Converting"""

mcp['Datetime'] = pd.to_datetime(mcp['Tarih'].astype(str) + ' ' + mcp['Saat'].astype(str))
production['Datetime'] = pd.to_datetime(production['Tarih'].astype(str) + ' ' + production['Saat'].astype(str))
consumption['Datetime'] = pd.to_datetime(consumption['Tarih'].astype(str) + ' ' + consumption['Saat'].astype(str))


"""
mcp = mcp.set_index('Datetime')
mcp = mcp.sort_index()
production = production.set_index('Datetime')
production = production.sort_index()
consumption = consumption.set_index('Datetime')
consumption = consumption.sort_index()
mcp = mcp.drop(['Tarih', 'Saat'], axis=1)
production = production.drop(['Tarih', 'Saat'],axis=1)
consumption = consumption.drop(['Tarih', 'Saat'],axis=1)"""

mcp['PTF (TL/MWh)'] = mcp['PTF (TL/MWh)'].str.replace('.','', regex=False).str.replace(',','.', regex=False)
mcp['PTF (TL/MWh)'] = pd.to_numeric(mcp['PTF (TL/MWh)'], errors='coerce')

mcp['PTF (USD/MWh)'] = mcp['PTF (USD/MWh)'].str.replace(',','.', regex=False)
mcp['PTF (USD/MWh)'] = pd.to_numeric(mcp['PTF (USD/MWh)'], errors='coerce')
mcp['PTF (EUR/MWh)'] = mcp['PTF (EUR/MWh)'].str.replace(',','.', regex=False)
mcp['PTF (EUR/MWh)'] = pd.to_numeric(mcp['PTF (EUR/MWh)'], errors='coerce')

consumption['Tüketim Miktarı(MWh)'] = consumption['Tüketim Miktarı(MWh)'].str.replace('.','',regex=False).str.replace(',', '.', regex=False)
consumption['Tüketim Miktarı(MWh)'] = pd.to_numeric(consumption['Tüketim Miktarı(MWh)'], errors='coerce')

change_cols = [col for col in production.columns if col not in ['Datetime', 'Tarih', 'Saat'] and production[col].dtype not in ['int64','float64']]

for col in change_cols:
    production[col] = production[col].str.replace(',','.', regex=False)
    production[col] = pd.to_numeric(production[col], errors='coerce')

mcp.isnull().sum()

production.describe().T

production.loc[production['Güneş'] < 0, 'Güneş'] = 0
production = production.drop(['Nafta', 'LNG'], axis=1) # All values of Nafta and LNG are zero.

"""## Merging Datasets"""

df = pd.merge(mcp, production,on=['Datetime', 'Tarih', 'Saat'], how='inner')
df = pd.merge(df, consumption, on=['Datetime', 'Tarih', 'Saat'], how= 'inner')

df.head()

"""# Exploratory Data Analysis (EDA)

## Grapping Categorical and Numerical Variables
"""

def grab_col_names(dataframe, cat_th=10, car_th=20):
    # cat_cols, cat_but_car
    cat_cols= [col for col in dataframe.columns if dataframe[col].dtypes == 'O']
    num_but_cat = [col for col in dataframe.columns if dataframe[col].dtypes != 'O' and
                   dataframe[col].nunique() < cat_th]
    cat_but_car = [col for col in dataframe.columns if dataframe[col].dtypes == 'O' and
                   dataframe[col].nunique() > car_th]
    cat_cols = cat_cols + num_but_cat
    cat_cols = [col for col in cat_cols if col not in cat_but_car]

    # num_cols
    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != 'O']
    num_cols = [col for col in num_cols if col not in num_but_cat ]

    print(f"Observations: {dataframe.shape[0]}")
    print(f"Variables: {dataframe.shape[1]}")
    print(f"cat_cols: {len(cat_cols)}")
    print(f"num_cols: {len(num_cols)}")
    print(f"cat_but_car: {len(cat_but_car)}")
    print(f"num_but_cat: {len(num_but_cat)}")
    return cat_cols, num_cols, cat_but_car

cat_cols, num_cols, cat_but_car = grab_col_names(df)

"""## Correlation Matrix"""

# Numerical Variables
f, ax = plt.subplots(figsize=[15,10])
sns.heatmap(df[num_cols].corr(), annot=True, fmt='.2f', ax=ax, cmap='magma')
ax.set_title('Correlation Matrix', fontsize=20)
plt.show()

# PTF - Tüketim İlişkisi
plt.figure(figsize=(15, 6))
plt.scatter(df['PTF (USD/MWh)'], df['Toplam'],
            alpha=0.3, s=10, c='blue',marker='o')
plt.xlabel('PTF (USD/MWh)')
plt.ylabel('Üretim Miktarı(MWh)')
plt.title('PTF - Üretim İlişkisi')
plt.grid(True, alpha=0.3)
plt.show()

# PTF - Tüketim İlişkisi
plt.figure(figsize=(15, 6))
plt.scatter(df['PTF (USD/MWh)'], df['Tüketim Miktarı(MWh)'],
            alpha=0.3, s=10, c='red',marker='o')
plt.xlabel('PTF (USD/MWh)')
plt.ylabel('Tüketim Miktarı(MWh)')
plt.title('PTF - Tüketim İlişkisi')
plt.grid(True, alpha=0.3)
plt.show()

# PTF
plt.figure(figsize=(10, 5))

df.groupby('Saat')['PTF (USD/MWh)'].mean().plot(kind='bar',
                                               color='skyblue',
                                               edgecolor='navy',
                                               alpha=0.7,
                                               width=0.8)

plt.xlabel('Saat')
plt.ylabel('Ortalama PTF (USD/MWh)')
plt.title('Saatlere Göre Ortalama PTF Değerleri')
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.show()

# Consumption
plt.figure(figsize=(10, 5))

df.groupby('Saat')['Tüketim Miktarı(MWh)'].mean().plot(kind='bar',
                                               color='darkblue',
                                               edgecolor='green',
                                               alpha=0.7,
                                               width=0.8)

plt.xlabel('Saat')
plt.ylabel('Tüketim Miktarı')
plt.title('Saatlere Göre Ortalama Tüketim Miktarı')
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.show()

# Production
plt.figure(figsize=(10, 5))

df.groupby('Saat')['Toplam'].mean().plot(kind='bar',
                                               color='green',
                                               edgecolor='orange',
                                               alpha=0.7,
                                               width=0.8)

plt.xlabel('Saat')
plt.ylabel('Toplam Enerji Üretimi')
plt.title('Saatlere Göre Ortalama Enerji Üretim Değerleri')
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.show()

# Sun Effect
plt.figure(figsize=(10, 5))

df.groupby('Saat')['Güneş'].mean().plot(kind='bar',
                                               color='orange',
                                               edgecolor='yellow',
                                               alpha=0.7,
                                               width=0.8)

plt.xlabel('Saat')
plt.ylabel('Güneş')
plt.title('Saatlere Göre Ortalama Güneş Enerjisi Üretim Değerleri')
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.show()

def num_summary(dataframe, col, plot=False,color='orange'):
    quantiles= [0.05, 0.25, 0.40, 0.60, 0.75, 0.95]
    print(dataframe[col].describe(quantiles).T)
    if plot:
        dataframe[col].hist(bins=20, color=color)
        plt.xlabel(col)
        plt.title(col)
        plt.show()
        print()

colors = ['orange', 'blue', 'green', 'red', 'purple', 'cyan', 'pink', 'gray', 'brown']
for i, col in enumerate(num_cols):
    num_summary(df, col, plot=True, color= colors[i % len(colors)])

"""## Outliers Problem"""

def outlier_thresholds(dataframe, col_name,  q1=0.05, q3=0.95):
    Q1 = dataframe[col_name].quantile(q1)
    Q3 = dataframe[col_name].quantile(q3)
    IQR = Q3 - Q1
    low = Q1 - 1.5*IQR
    up = Q3 + 1.5*IQR
    return low, up

def grab_outliers(dataframe, col_name, index=False):
    low, up = outlier_thresholds(dataframe, col_name)
    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up) )].shape[0] > 10:
      print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up) )].head(10))
    else:
      print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up) )])
    if index:
      outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up) )].index
      return outlier_index

number =1
for col in num_cols:
    print(number, '.', col.upper(), end='\n\n')
    grab_outliers(df, col)
    number += 1

def replace_with_thresholds(dataframe, col):
    low, up = outlier_thresholds(dataframe,col)
    dataframe.loc[dataframe[col] < low, col] = low
    dataframe.loc[dataframe[col] > up, col] = up

for col in num_cols:
  replace_with_thresholds(df,col)

"""# Feature Engineering

## Seasonality
"""

# Monthly Based PTF
df['Month'] = df['Datetime'].dt.month
monthly_avg = df.groupby('Month')['PTF (TL/MWh)'].agg(['mean', 'std'])

fig, ax = plt.subplots(figsize=(12, 5))
ax.plot(monthly_avg.index, monthly_avg['mean'], marker='o', linewidth=2,
        color='green', label='Ortalama')
ax.fill_between(monthly_avg.index,
                monthly_avg['mean'] - monthly_avg['std'],
                monthly_avg['mean'] + monthly_avg['std'],
                alpha=0.3, color='green', label='±1 Std Dev')
ax.set_title('Aylık PTF Pattern (2 Yıllık Veri)', fontsize=14, fontweight='bold')
ax.set_xlabel('Ay')
ax.set_ylabel('PTF (TL/MWh)')
ax.set_xticks(range(1, 13))
ax.set_xticklabels(['Oca', 'Şub', 'Mar', 'Nis', 'May', 'Haz',
                     'Tem', 'Ağu', 'Eyl', 'Eki', 'Kas', 'Ara'])
ax.legend()
ax.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# Daily based - 0=Monday, 6=Sunday
df['DayOfWeek'] = df['Datetime'].dt.dayofweek
df['DayName'] = df['Datetime'].dt.day_name()


daily_avg = df.groupby('DayName')['PTF (TL/MWh)'].mean()
# Sıralı göstermek için
day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
daily_avg = daily_avg.reindex(day_order)
daily_avg.plot(kind='bar', figsize=(10,5))
plt.title('Günlük Ortalama PTF')

# Hafta içi vs hafta sonu ayrı ayrı
df['IsWeekend'] = df['DayOfWeek'].isin([5,6])

fig, ax = plt.subplots(1, 2, figsize=(15,5))

# Hafta içi
weekday_hourly = df[~df['IsWeekend']].groupby('Saat')['PTF (TL/MWh)'].mean()
weekday_hourly.plot(ax=ax[0], marker='o', title='Hafta İçi Saatlik PTF')

# Hafta sonu
weekend_hourly = df[df['IsWeekend']].groupby('Saat')['PTF (TL/MWh)'].mean()
weekend_hourly.plot(ax=ax[1], marker='o', title='Hafta Sonu Saatlik PTF')

"""* We can conclude that electricity prices are cheap during the weekend daytime and high during weekday rush hour.
* The reason for the difference in the graphs around 7-9 o'clock may be the hours to go to work.

## Time Series Decomposition
"""

daily_ptf = df.set_index('Datetime')['PTF (TL/MWh)'].resample('D').mean()

# Decompose
decomposition = seasonal_decompose(daily_ptf, model='additive', period=365)

fig, axes = plt.subplots(4, 1, figsize=(15,10))
decomposition.observed.plot(ax=axes[0], title='Observed')
decomposition.trend.plot(ax=axes[1], title='Trend')
decomposition.seasonal.plot(ax=axes[2], title='Seasonal')
decomposition.resid.plot(ax=axes[3], title='Residual')
plt.tight_layout()

daily_ptf = df.set_index('Datetime')['PTF (USD/MWh)'].resample('D').mean()

# Decompose
decomposition = seasonal_decompose(daily_ptf, model='additive', period=365)

fig, axes = plt.subplots(4, 1, figsize=(15,10))
decomposition.observed.plot(ax=axes[0], title='Observed')
decomposition.trend.plot(ax=axes[1], title='Trend')
decomposition.seasonal.plot(ax=axes[2], title='Seasonal')
decomposition.resid.plot(ax=axes[3], title='Residual')
plt.tight_layout()

"""###

### Heatmap
"""

pivot_table = df.pivot_table(values='PTF (TL/MWh)',
                               index='Saat',
                               columns='DayName',
                               aggfunc='mean')

plt.figure(figsize=(10,8))
sns.heatmap(pivot_table, cmap='YlOrRd', annot=True, fmt='.0f')
plt.title('Ortalama PTF - Saat vs Gün')
plt.xlabel('Günler')
plt.ylabel('Saatler')

"""## Renewable Energy Analysis"""

# Renewable penetration
df['Renewable_Total'] = df['Rüzgar'] + df['Güneş'] + df['Barajlı'] + df['Akarsu'] + df['Biyokütle'] + df['Jeotermal'] + df['Atık Isı']
df['Renewable_Share'] = df['Renewable_Total'] / df['Toplam'] * 100

# Scatter plot
plt.scatter(df['Renewable_Share'], df['PTF (TL/MWh)'], alpha=0.3)
plt.xlabel('Renewable Share (%)')
plt.ylabel('PTF (TL/MWh)')
plt.title('Yenilenebilir Enerji Oranı vs PTF')

# Correlation
print(f"Renewable Share vs PTF correlation: {df['Renewable_Share'].corr(df['PTF (USD/MWh)']):.3f}", end='\n\n')

"""* As the renewable energy rate increases, the PTF decreases.
* In other words, there is an inverse correlation between the two.

## Fossil Fuel Share
"""

df['Fossil_Share'] = (df['Doğal Gaz'] + df['İthal Kömür'] + df['Asfaltit Kömür'] + df['Taş Kömür'] + df['Fuel Oil']) / df['Toplam']

"""## Supply-Demand Balance"""

df['Supply_Demand_Ratio'] = df['Toplam'] / df['Tüketim Miktarı(MWh)']
df['Supply_Demand_Gap'] = df['Toplam'] - df['Tüketim Miktarı(MWh)']

plt.scatter(df['Supply_Demand_Ratio'], df['PTF (TL/MWh)'], alpha=0.3)
plt.xlabel('Arz/Talep Oranı')
plt.ylabel('PTF')
plt.axvline(x=1, color='r', linestyle='--', label='Balance')
plt.legend()

"""* In general, it appears that supply is not meeting demand. Türkiye is a country dependent on foreign energy."""

# Yüksek talep + düşük renewable = yüksek fiyat
df['Demand_x_LowRenewable'] = df['Tüketim Miktarı(MWh)'] * (1 - df['Renewable_Share'])

"""## Extreme Events"""

# En pahalı 100 saat
top_100 = df.nlargest(100, 'PTF (TL/MWh)')

# Bunlar hangi saatlerde/günlerde oluyor?
print(top_100['Saat'].value_counts().head(), end='\n\n')
print(top_100['Month'].value_counts().head(), end='\n\n')
print(top_100['DayOfWeek'].value_counts().head(), end='\n\n')

# Renewable share bu saatlerde nasıl?
print(f"Avg renewable share in top 100 expensive hours: {top_100['Renewable_Share'].mean():.1f}%")

"""* Expensive Hours: between 18-22
* Expensive Months: April and May
* Expensive Days: not certain
"""

df['Saat'].dtypes

df['Saat'] = df['Saat'].str[0:2].astype(int)

df['IsPeakHour'] = df['Saat'].isin([18, 19, 20, 21, 22]).astype(int)

# Peak saat + yüksek talep
df['Peak_x_Demand'] = df['IsPeakHour'] * df['Tüketim Miktarı(MWh)']

"""## Lag features"""

# Geçmiş PTF değerleri - önceki saatin fiyatı güçlü predictor
df['PTF_lag1'] = df['PTF (TL/MWh)'].shift(1)  # 1 saat önceki fiyat
df['PTF_lag24'] = df['PTF (TL/MWh)'].shift(24)  # Dün aynı saat
df['PTF_lag168'] = df['PTF (TL/MWh)'].shift(168)  # Geçen hafta aynı saat

"""## Rolling Statistics"""

# Son 24 saatin ortalaması
df['PTF_rolling_24h_mean'] = df['PTF (TL/MWh)'].shift(1).rolling(24).mean()
df['PTF_rolling_weekly_mean'] = df['PTF (TL/MWh)'].shift(1).rolling(168).mean()
df['PTF_rolling_24h_std'] = df['PTF (TL/MWh)'].shift(1).rolling(24).std()
df['PTF_rolling_weekly_std'] = df['PTF (TL/MWh)'].shift(1).rolling(168).std()

"""## Cyclic features"""

# Cyclic features - saatlik ve aylık döngüsellik
# Modelin saat 0 ile saat 23'ün çok farklı olmadığını anlaması için bu işlem gerekiyor.
df['Saat'] = df['Saat'].astype(int)
df['Month'] = df['Month'].astype(int)
df['DayOfWeek'] = df['DayOfWeek'].astype(int)

df['Hour_sin'] = np.sin(2 * np.pi * df['Saat'] / 24)
df['Hour_cos'] = np.cos(2 * np.pi * df['Saat'] / 24)

df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)
df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)

df['DayOfWeek_sin'] = np.sin(2 * np.pi * df['DayOfWeek'] / 7)
df['DayOfWeek_cos'] = np.cos(2 * np.pi * df['DayOfWeek'] / 7)

print("Cyclic features oluşturuldu:")
print(df[['Saat', 'Hour_sin', 'Hour_cos']].head())

"""## Holidays"""

# Türkiye resmi tatilleri
holidays = ['2023-10-29','2024-01-01', '2024-04-10','2024-04-11','2024-04-12','2024-04-23', '2024-05-01', '2024-05-19',
            '2024-06-15','2024-06-16','2024-06-17','2024-06-18', '2024-07-15', '2024-08-30', '2024-10-29',
            '2025-01-01', '2025-03-29','2025-03-30','2025-03-31','2025-04-01', '2025-05-01', '2025-05-19',
            '2025-06-06','2025-06-07','2025-06-08','2025-06-09', '2025-07-15', '2025-08-30', '2025-10-29']
df['IsHoliday'] = df['Datetime'].dt.date.astype(str).isin(holidays).astype(int)

"""## Exponentially Weighted Mean Features"""

#Exponentially Weighted Mean Features
"""
def ewm_features(dataframe, alphas, lags):
    for alpha in alphas:
        for lag in lags:
            dataframe['Transaction_ewm_alpha_' + str(alpha).replace(".", "") + "_lag_" + str(lag)] = \
                dataframe.groupby(["merchant_id"])['Total_Transaction'].transform(lambda x: x.shift(lag).ewm(alpha=alpha).mean())
    return dataframe

alphas = [0.95, 0.8, 0.5]
lags = [24, 168, 720]

df = ewm_features(df, alphas, lags)
"""

"""# Selection of Variables"""

df.head()

"""## Encoding"""

target_col = 'PTF (TL/MWh)'
cycling_cols = ['Hour_sin','Hour_cos','Month_sin','Month_cos','DayOfWeek_sin',	'DayOfWeek_cos'] # They are already in scaled form.

cat_cols, num_cols, cat_but_car = grab_col_names(df)

cat_cols = [col for col in cat_cols if col not in cycling_cols and col not in ['DayOfWeek','DayName']]
num_cols = [col for col in num_cols if col not in cycling_cols]

cat_cols

num_cols

# We choose the correct numeric variables.
num_cols = [ # Main generation
            'Doğal Gaz', 'Rüzgar', 'Barajlı', 'Uluslararası', 'Güneş',

            # Shares
            'Renewable_Share','Fossil_Share',

            # Demand/Supply
            'Toplam', 'Tüketim Miktarı(MWh)', 'Supply_Demand_Ratio',

            # Lag and Rolling Features
            'PTF_lag1', 'PTF_lag24', 'PTF_lag168', 'PTF_rolling_24h_mean',
            'PTF_rolling_weekly_mean','PTF_rolling_24h_std', 'PTF_rolling_weekly_std']

df_ = df.copy()

df = df[cat_cols + num_cols + cycling_cols + [target_col]]

df['IsWeekend'] = df['IsWeekend'].astype(int)

def one_hot_encoder(dataframe, categorical_cols, drop_first=False):
    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)
    return dataframe

#df = one_hot_encoder(df, cat_cols, drop_first=True)

# We did not use this function because our categorical cols already are the way zero-one

df[cat_cols].value_counts().head()

"""# Scaling"""

# Important! We use df_ because we seperated some columns like Datetime for modelling.

df_['Datetime'].min(), df_['Datetime'].max()

split_date = '2025-07-30 00:00:00'
train = df[df_['Datetime']<= split_date]
test = df[df_['Datetime']> split_date]

train_ = df_[df_['Datetime']<= split_date]
test_ = df_[df_['Datetime']> split_date]

len(train), len(test)

X_train = train.drop('PTF (TL/MWh)', axis=1)
y_train = train['PTF (TL/MWh)']
X_test = test.drop('PTF (TL/MWh)', axis=1)
y_test = test['PTF (TL/MWh)']

#StandardScaler
"""
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
"""

# We did not use Scaler because we will use Tree-based algorithms.

"""# MODEL"""

# We did not use train_test_split method because we already splitted test and train sets.

"""## Baseline"""

# Naive forecast - dün aynı saat
y_pred_baseline = test['PTF_lag24']

mae_baseline = mean_absolute_error(y_test, y_pred_baseline)
rmse_baseline = np.sqrt(mean_squared_error(y_test, y_pred_baseline))
r2_baseline = r2_score(y_test, y_pred_baseline)

print("=== BASELINE (PTF_lag24) ===")
print(f"MAE: {mae_baseline:.2f}")
print(f"RMSE: {rmse_baseline:.2f}")
print(f"R²: {r2_baseline:.3f}")

"""## Random Forest"""

rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=20,
    min_samples_split=5,
    random_state=42,
    n_jobs=-1
)

rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

mae_rf = mean_absolute_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)

print("\n=== RANDOM FOREST ===")
print(f"MAE: {mae_rf:.2f}")
print(f"RMSE: {rmse_rf:.2f}")
print(f"R²: {r2_rf:.3f}")

"""## XGBoost"""

xgb_model = XGBRegressor(
    n_estimators=200,
    max_depth=8,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    n_jobs=-1
)

xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)

mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
r2_xgb = r2_score(y_test, y_pred_xgb)

print("\n=== XGBOOST ===")
print(f"MAE: {mae_xgb:.2f}")
print(f"RMSE: {rmse_xgb:.2f}")
print(f"R²: {r2_xgb:.3f}")

"""## LGBM"""

lgb_model = LGBMRegressor(
    n_estimators=200,
    max_depth=8,
    learning_rate=0.1,
    num_leaves=31,
    random_state=42,
    n_jobs=-1
)

lgb_model.fit(X_train, y_train)
y_pred_lgb = lgb_model.predict(X_test)

mae_lgb = mean_absolute_error(y_test, y_pred_lgb)
rmse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_lgb))
r2_lgb = r2_score(y_test, y_pred_lgb)

print("\n=== LIGHTGBM ===")
print(f"MAE: {mae_lgb:.2f}")
print(f"RMSE: {rmse_lgb:.2f}")
print(f"R²: {r2_lgb:.3f}")

"""## Comparison Results"""

results = pd.DataFrame({
    'Model': ['Baseline', 'Random Forest', 'XGBoost', 'LightGBM'],
    'MAE': [mae_baseline, mae_rf, mae_xgb, mae_lgb],
    'RMSE': [rmse_baseline, rmse_rf, rmse_xgb, rmse_lgb],
    'R²': [r2_baseline, r2_rf, r2_xgb, r2_lgb]
})

print("\n=== MODEL Comparison ===")
print(results.to_string(index=False))

"""* Day-ahead price estimation in academic literature:

* R² > 0.80: Excellent ✓
* MAPE < 15%: Good (~7-8% of your value)
* MAE < 200: Strong ✓

# Feature Importance
"""

# LGBM feature importance
feature_importance = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': lgb_model.feature_importances_
}).sort_values('Importance', ascending=False)

print("\n=== TOP 10 FEATURES ===")
print(feature_importance.head(10))

plt.figure(figsize=(10, 6))
feature_importance.head(15).plot(x='Feature', y='Importance', kind='barh')
plt.title('Feature Importance - LGBM')
plt.xlabel('Importance')
plt.tight_layout()
plt.show()

"""# Residuals
* Are residuals random or is there a pattern?
"""

residuals = y_test - y_pred_lgb

# A) Residual Distribution
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Histogram
axes[0].hist(residuals, bins=50, edgecolor='black', alpha=0.7)
axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2)
axes[0].set_title('Residual Distribution', fontsize=12, fontweight='bold')
axes[0].set_xlabel('Residuals (TL/MWh)')
axes[0].set_ylabel('Frequency')
axes[0].grid(alpha=0.3)

# QQ Plot - normality control
from scipy import stats
stats.probplot(residuals, dist="norm", plot=axes[1])
axes[1].set_title('Q-Q Plot', fontsize=12, fontweight='bold')
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.show()

# B) Residuals vs Predicted Values
plt.figure(figsize=(12, 5))
plt.scatter(y_pred_lgb, residuals, alpha=0.3)
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('Predicted PTF (TL/MWh)')
plt.ylabel('Residuals (TL/MWh)')
plt.title('Residuals vs Predicted Values', fontweight='bold')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# C) Residuals Over Time
test_with_pred = test_.copy()
test_with_pred['Predictions'] = y_pred_lgb
test_with_pred['Residuals'] = residuals

plt.figure(figsize=(15, 5))
plt.plot(test_with_pred['Datetime'], test_with_pred['Residuals'], alpha=0.6)
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('Date')
plt.ylabel('Residuals (TL/MWh)')
plt.title('Residuals Over Time', fontweight='bold')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# İstatistikler
print("=== RESIDUAL ANALİZİ ===")
print(f"Mean: {residuals.mean():.2f} (0'a yakın olmalı)")
print(f"Std Dev: {residuals.std():.2f}")
print(f"Min: {residuals.min():.2f}")
print(f"Max: {residuals.max():.2f}")
print(f"\nSkewness: {stats.skew(residuals):.3f} (0'a yakın = simetrik)")
print(f"Kurtosis: {stats.kurtosis(residuals):.3f} (0'a yakın = normal)")

"""# Prediction Plot"""

# A) Scatter Plot
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_lgb, alpha=0.4)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
         'r--', linewidth=2, label='Perfect Prediction')
plt.xlabel('Actual PTF (TL/MWh)')
plt.ylabel('Predicted PTF (TL/MWh)')
plt.title(f'Actual vs Predicted - LightGBM (R²={r2_lgb:.3f})', fontweight='bold')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# B) Time Series Plot (First 7 days)
plt.figure(figsize=(15, 6))
plot_days = 7 * 24  # 7 gün
plt.plot(test_with_pred['Datetime'][:plot_days],
         test_with_pred['PTF (TL/MWh)'][:plot_days],
         label='Actual', linewidth=2, alpha=0.7)
plt.plot(test_with_pred['Datetime'][:plot_days],
         test_with_pred['Predictions'][:plot_days],
         label='Predicted', linewidth=2, alpha=0.7)
plt.xlabel('Date')
plt.ylabel('PTF (TL/MWh)')
plt.title('Actual vs Predicted - First 7 Days', fontweight='bold')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# C) Error Distribution by Hour
test_with_pred['Hour'] = test_with_pred['Datetime'].dt.hour
test_with_pred['Absolute_Error'] = abs(test_with_pred['Residuals'])

hourly_error = test_with_pred.groupby('Hour')['Absolute_Error'].mean()

plt.figure(figsize=(12, 5))
hourly_error.plot(kind='bar', color='coral', edgecolor='black')
plt.xlabel('Hour of Day')
plt.ylabel('Mean Absolute Error (TL/MWh)')
plt.title('Prediction Error by Hour', fontweight='bold')
plt.xticks(rotation=0)
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

"""# Trading Strategy"""

#At 2:00 PM:
# Actual PTF = 2000 TL
# Predicted 3:00 PM PTF = 2100 TL

# Forecast > Actual → Signal = 1 (LONG)
# In other words: "Price will rise, BUY"


test_with_pred['Price_Change'] = test_with_pred['PTF (TL/MWh)'].diff()

test_with_pred['Signal'] = 0
test_with_pred.loc[test_with_pred['Predictions'] > test_with_pred['PTF (TL/MWh)'], 'Signal'] = 1  # LONG
test_with_pred.loc[test_with_pred['Predictions'] < test_with_pred['PTF (TL/MWh)'], 'Signal'] = -1  # SHORT

test_with_pred['PnL'] = test_with_pred['Signal'].shift(1) * test_with_pred['Price_Change']
test_with_pred['PnL'] = test_with_pred['PnL'].fillna(0)

# Cumulative PnL
test_with_pred['Cumulative_PnL'] = test_with_pred['PnL'].cumsum()

# Metrics
total_pnl = test_with_pred['PnL'].sum()
profitable_trades = (test_with_pred['PnL'] > 0).sum()
total_trades = (test_with_pred['PnL'] != 0).sum()
win_rate = (profitable_trades / total_trades * 100) if total_trades > 0 else 0

# Sharpe ratio (daily returns)
daily_returns = test_with_pred['PnL']
sharpe = (daily_returns.mean() / daily_returns.std() * np.sqrt(24*365)) if daily_returns.std() > 0 else 0

# Maximum drawdown
cumulative = test_with_pred['Cumulative_PnL']
running_max = cumulative.expanding().max()
drawdown = cumulative - running_max
max_drawdown = drawdown.min()

print("=== TRADING STRATEGY RESULTS ===")
print(f"Total PnL: {total_pnl:.2f} TL")
print(f"Win Rate: {win_rate:.1f}%")
print(f"Total Trades: {total_trades}")
print(f"Profitable Trades: {profitable_trades}")
print(f"Sharpe Ratio: {sharpe:.2f}")
print(f"Max Drawdown: {max_drawdown:.2f} TL")

# Visualization
fig, axes = plt.subplots(2, 1, figsize=(15, 10))

# Cumulative PnL
axes[0].plot(test_with_pred['Datetime'], test_with_pred['Cumulative_PnL'], linewidth=2)
axes[0].axhline(y=0, color='red', linestyle='--', alpha=0.5)
axes[0].set_xlabel('Date')
axes[0].set_ylabel('Cumulative PnL (TL)')
axes[0].set_title('Trading Strategy - Cumulative PnL', fontweight='bold')
axes[0].grid(alpha=0.3)

# Drawdown
axes[1].fill_between(test_with_pred['Datetime'], drawdown, 0, alpha=0.3, color='red')
axes[1].plot(test_with_pred['Datetime'], drawdown, color='red', linewidth=1)
axes[1].set_xlabel('Date')
axes[1].set_ylabel('Drawdown (TL)')
axes[1].set_title('Drawdown Over Time', fontweight='bold')
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.show()